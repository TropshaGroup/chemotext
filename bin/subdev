#!/bin/bash

set +x

if [ -z "$STARS_HOME" ]; then
    echo STARS_HOME must be set
    exit 1
fi

echo STARS_HOME: $STARS_HOME

FRAMEWORK_NAME="Chemotext:Pipeline[Scala]"

dev () {
    APP_HOME=$STARS_HOME/chemotext
    SPARK_HOME=$STARS_HOME/spark/current
    DATA_HOME=$STARS_HOME/data
    MESHXML=$STARS_HOME/data/pubmed/mesh/desc2016_2.xml
    TMCHEM_HOME=$STARS_HOME/data/tmchem
    SAMPLESIZE=0.001
    env=dev

    MESOS_MASTER=local[2]

    ARG_MESOS_MASTER="--master $MESOS_MASTER"
    ARG_EXECUTOR_MEMORY=10G
    ARG_TOTAL_EXECUTOR_CORES=2
    ARG_NUM_EXECUTORS=2
    ARG_DRIVER_MEMORY=15G
    ARG_TASK_CPUS=1
    ARG_DEFAULT_PARALLELISM=2
    ARG_MAX_RESULT_SIZE=1G
}
test () {
    dev

    DATA_HOME=$STARS_HOME/chemotext/data
    TMCHEM_HOME=$APP_HOME/data/tmchem
    SAMPLESIZE=1
    env=test
}
prod () {
    APP_HOME=$STARS_HOME/app/chemotext
    SPARK_HOME=$STARS_HOME/stack/spark/current
    DATA_HOME=$STARS_HOME/var/chemotext
    MESHXML=$DATA_HOME/mesh/desc2016_2.xml
    TMCHEM_HOME=$DATA_HOME/tmchem
    SAMPLESIZE=0.001
    env=prod

    ARG_MESOS_MASTER=
    ARG_EXECUTOR_MEMORY=70G
    ARG_TOTAL_EXECUTOR_CORES=200
    ARG_NUM_EXECUTORS=20
    ARG_DRIVER_MEMORY=3G
    ARG_TASK_CPUS=10
    ARG_DEFAULT_PARALLELISM=200
    ARG_MAX_RESULT_SIZE=4G

    export MESOS_MASTER=stars-c1.edc.renci.org:5050
    export MESOS_MASTER=$(hostname):5050
    echo mesos master: $MESOS_MASTER
    echo spark home: $SPARK_HOME
}

#test
prod 


set -x
PUBMEDC=$DATA_HOME/pubmed/articles
CTDACPATH=$DATA_HOME/ctd/CTD_chemicals_diseases.csv
CTDABPATH=$DATA_HOME/ctd/CTD_chem_gene_ixns.csv
CTDBCPATH=$DATA_HOME/ctd/CTD_genes_diseases.csv
NORMALIZER_CONFIGPATH=$TMCHEM_HOME/config/banner_JOINT_${env}.xml
NORMALIZER_CACHEFILE=$TMCHEM_HOME/cacheFile.tsv
NORMALIZER_DICTIONARY=$TMCHEM_HOME/data/dict.txt
OUTPUTPATH=$DATA_HOME/output
set +x

genTmChemConfig () {
    rm -rf $NORMALIZER_CONFIGPATH
    cat <<EOF >> $NORMALIZER_CONFIGPATH
<?xml version="1.0" encoding="iso-8859-1"?>
<banner-configuration>
  <banner>
    <eval>
      <datasetName>banner.eval.dataset.PubtatorDataset</datasetName>
      <dataset> 
        <dataFilename>${TMCHEM_HOME}/data/CHEMDNER_BC5CDR.txt</dataFilename>
        <foldType>Chemical</foldType>
      </dataset>
      <idInputFilename>${TMCHEM_HOME}/output/ids.txt</idInputFilename>
      <rawInputFilename>${TMCHEM_HOME}/output/raw.txt</rawInputFilename>
      <trainingInputFilename>${TMCHEM_HOME}/output/training.txt</trainingInputFilename>
      <outputFilename>${TMCHEM_HOME}/output/output.txt</outputFilename>
      <inContextAnalysisFilename>${TMCHEM_HOME}/output/contextAnalysis.html</inContextAnalysisFilename>
      <mentionFilename>${TMCHEM_HOME}/output/mention.txt</mentionFilename>
      <modelFilename>${TMCHEM_HOME}/output/model_JOINT_O1.bin</modelFilename>
      <lemmatiserDataDirectory>${TMCHEM_HOME}/nlpdata/lemmatiser</lemmatiserDataDirectory>
      <posTaggerDataDirectory>${TMCHEM_HOME}/nlpdata/tagger</posTaggerDataDirectory>
      <posTagger>dragon.nlp.tool.HeppleTagger</posTagger>
      <tokenizer>banner.tokenization.FineTokenizer</tokenizer>
      <useParenthesisPostProcessing>true</useParenthesisPostProcessing>
      <useLocalAbbreviationPostProcessing>true</useLocalAbbreviationPostProcessing>
      <useNumericNormalization>true</useNumericNormalization>
      <tagFormat>IOB</tagFormat>
      <crfOrder>1</crfOrder>
      <textDirection>Forward</textDirection>
      <mentionTypes>Required</mentionTypes>
      <sameTypeOverlapOption>Union</sameTypeOverlapOption>
      <differentTypeOverlapOption>Exception</differentTypeOverlapOption>
    </eval>
  </banner>
</banner-configuration>
EOF
}

genTmChemConfig

cd $APP_HOME
export JAVA_OPTS="-Xmx10G -Xms10G"

$SPARK_HOME/bin/spark-submit \
    --class "org.chemotext.PipelineApp" \
    $ARG_MESOS_MASTER \
    --executor-memory $ARG_EXECUTOR_MEMORY \
    --total-executor-cores $ARG_TOTAL_EXECUTOR_CORES \
    --num-executors $ARG_NUM_EXECUTORS  \
    --driver-memory $ARG_DRIVER_MEMORY \
    --conf spark.task.cpus=$ARG_TASK_CPUS \
    --conf spark.default.parallelism=$ARG_DEFAULT_PARALLELISM \
    --conf spark.driver.maxResultSize=$ARG_MAX_RESULT_SIZE \
    $( find $APP_HOME -name "*assembly*.jar" -print | grep scala ) \
    $FRAMEWORK_NAME \
    $APP_HOME \
    $PUBMEDC \
    $MESHXML \
    $SAMPLESIZE \
    $CTDACPATH \
    $CTDABPATH \
    $CTDBCPATH \
    $OUTPUTPATH \
    $NORMALIZER_CONFIGPATH \
    $NORMALIZER_CACHEFILE \
    $NORMALIZER_DICTIONARY
