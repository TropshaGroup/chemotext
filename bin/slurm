#!/bin/bash

#SBATCH --job-name=chemotext
#SBATCH --nodes=2
#SBATCH --time=100:00:00
#SBATCH --mem=80000
#SBATCH --cpus-per-task=4
#SBATCH --partition=batch
#SBATCH --qos=short
#SBATCH --output="/home/scox/dev/chemotext/chemotext-%j.stdout"
#SBATCH --error="/home/scox/dev/chemotext/chemotext-%j.stderr"

set -x
source ~/.bashrc
source bin/slurm-conf.sh
ENV=hatteras
SPARK_APP=bin/sub
APP=ct2

start_cluster () {
    export JAVA_OPTS="-Xms10G -Xmx10G"
    MASTER=$(hostname)
    srun $SPARK_ON_SLURM/start-cluster.sh $MASTER &
    sleep 10
}

start_app () {
# Make dynamic:
    export STARS_HOME=/projects/stars
    
    $SPARK_APP \
	--master=spark://$MASTER:7077 \
	--env=$ENV \
	--app=$APP
    echo Ending Spark cluster execution.
}
getarg () {
    echo $1 | sed s,.*=,,
}
main () {    
    for arg in $*; do
        case $arg in
            --sapp\=*)
                export SPARK_APP=$(getarg $arg)
                shift;;
            --app\=*)
                APP=$(getarg $arg)
                shift;;
	    --env\=*)
	        ENV=$(getarg $arg)
	        shift;;
        esac
    done
    start_cluster
    start_app
}

main $*

exit 0
