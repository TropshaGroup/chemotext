#!/bin/bash

#SBATCH --job-name=chemotext
#SBATCH --nodes=2
#SBATCH --time=100:00:00
#SBATCH --mem=80000
#SBATCH --cpus-per-task=4
#SBATCH --partition=batch
#SBATCH --qos=short
#SBATCH --output="/home/scox/dev/chemotext/chemotext-%j.stdout"
#SBATCH --error="/home/scox/dev/chemotext/chemotext-%j.stderr"

set -x
source ~/.bashrc
source bin/slurm-conf.sh
ENV=hatteras
SPARK_APP=bin/sub

getarg () {
    echo $1 | sed s,.*=,,
}   
main () {    
    for arg in $*; do
        case $arg in
            --sapp\=*)
                export SPARK_APP=$(getarg $arg)
                shift;;
            --app\=*)
                APP=$(getarg $arg)
                shift;;
	    --env\=*)
	        ENV=$(getarg $arg)
	        shift;;
        esac
    done
}

export JAVA_OPTS="-Xms10G -Xmx10G"
MASTER=$(hostname)
srun $SPARK_ON_SLURM/start-cluster.sh $MASTER &
sleep 10

# Make dynamic:
export STARS_HOME=/projects/stars

$SPARK_APP \
    --master=spark://$MASTER:7077 \
    --env=$ENV \
    --app=$APP

echo Ending Spark cluster execution.

main $*

exit 0


#SBATCH --ntasks-per-node=4
